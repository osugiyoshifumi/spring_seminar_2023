{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJU2RPpSvlQT"
      },
      "source": [
        "# データ拡張（Data Augmentation）\n",
        "\n",
        "\n",
        "---\n",
        "## 目的\n",
        "CIFAR10 Datasetを用いて10クラスの物体認識を行う．プログラムの構成は，MNISTによる文字認識のプログラムと同様になっているため，基礎的な説明はそちらを参照して頂きたい．このページでは，MNISTによる文字認識のプログラムとの差分について書いていく．\n",
        "\n",
        "GPUを用いたネットワークの計算を行う．\n",
        "また，Data Augmentationを用いた学習の効果について確認する．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQGfxWYK_4O"
      },
      "source": [
        "## 準備\n",
        "\n",
        "### Google Colaboratoryの設定確認・変更\n",
        "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
        "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tsYagqvloK"
      },
      "source": [
        "## 使用するデータセット\n",
        "\n",
        "### データセット\n",
        "今回の物体認識では，CIFAR10データセットを用いる．CIFAR10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットである．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo4jjpmwvle1"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートする．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算をChainerで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iCeaCulfvlao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436cedac-eddf-48fc-ab8d-d585202e6347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use CUDA: True\n"
          ]
        }
      ],
      "source": [
        "# モジュールのインポート\n",
        "from time import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppjeW5MbysXC"
      },
      "source": [
        "## データセットの読み込みとData Augmentation\n",
        "学習データ（CIFAR10データセット）を読み込みます．\n",
        "\n",
        "この時，学習およびテスト画像に対する前処理`transform_train`および`transform_test`を定義します．\n",
        "`transform_train`は，`transforms.Compose()`を用いて定義します．\n",
        "`transforms.Compose()`では，引数に指定した処理を行った画像データを返し，学習または評価に使用するように定義を行います．\n",
        "\n",
        "### augmentationなしの場合\n",
        "まず．augmentationなしの場合の定義について説明します．\n",
        "ここでは，`transforms.Compose([transforms.ToTensor()])`のように，引数として，`transforms.ToTensor()`関数が格納されたリストを入力します．\n",
        "これにより，データをpytorchで扱うことのできる`Tensor`型の配列に変換すると同時に，`[0, 255]`の画素値を`[0.0, 1.0]`に正規化を行ったものを返す処理を実現しています．\n",
        "\n",
        "### augmentationありの場合\n",
        "何かしらのAugmentationを適用する場合には，`transforms.Compose()`の引数に，行いたい処理の関数をリストとして用意します．\n",
        "下の例では，\n",
        "```\n",
        "[transforms.RandomCrop(32, padding=1),\n",
        " transforms.RandomHorizontalFlip(),\n",
        " transforms.ToTensor()]\n",
        "```\n",
        "という3種類の関数をリストに格納し，`transfomrs.Compose()`の引数へ入力しています．\n",
        "`RandomCrop()`は画像をランダムに切り取り，CIFAR10の画像サイズである32×32 pixelsにリサイズして返す処理を定義しています．\n",
        "また，`RandomHorizontalFlip()`では，ランダムに左右反転を行う処理を定義しています．\n",
        "最後に，Augmentationを行った画像データを`Tensor`型の配列へ変換・画素値を正規化し返すように定義しています．\n",
        "\n",
        "一方で，テストデータには，Augmentationを適用しないため，`ToTensor()`関数のみを使用するように定義しています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K_xx-TkVvls6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d827e6-094e-402a-ad9c-ed368e210b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13016053.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "# augmentationなし #####\n",
        "transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# augmentationあり #####\n",
        "# transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n",
        "#                                       transforms.RandomHorizontalFlip(),\n",
        "#                                       transforms.ToTensor()])\n",
        "# transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "畳み込みニューラルネットワークを定義します．\n",
        "\n",
        "ここでは，畳み込み層２層，全結合層３層から構成されるネットワークとします．\n",
        "\n",
        "１層目の畳み込み層は入力チャンネル数が3，出力する特徴マップ数が16，畳み込むフィルタサイズが3x3です．２層目の畳み込み層は入力チャネル数が16．出力する特徴マップ数が32，畳み込むフィルタサイズは同じく3x3です．１つ目の全結合層は入力ユニット数は`8*8*32`とし，出力は1024としています．次の全結合層入力，出力共に1024，出力層は入力が1024，出力が10です．これらの各層の構成を`__init__`関数で定義します．\n",
        "\n",
        "次に，`forward`関数では，定義した層を接続して処理するように記述します．`forward`関数の引数xは入力データです．それを`__init__`関数で定義したconv1に与え，その出力を活性化関数であるrelu関数に与えます．そして，その出力をmax_pooling_2dに与えて，プーリング処理結果をhとして出力します．hはconv2に与えられて畳み込み処理とプーリング処理を行います．そして，出力hをl1に与えて全結合層の処理を行います．最終的にl3の全結合層の処理を行った出力hを戻り値としています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.relu(self.conv1(x)))\n",
        "        h = self.pool(self.relu(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.relu(self.l1(h))\n",
        "        h = self.relu(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dwuvfouzmd7"
      },
      "source": [
        "## ネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "\n",
        "CNNクラスを呼び出して，ネットワークモデルを定義します． また，GPUを使う場合（use_cuda == True）には，ネットワークモデルをGPUメモリ上に配置します． これにより，GPUを用いた演算が可能となります．\n",
        "\n",
        "学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します． また，学習率を0.01，モーメンタムを0.9として引数に与えます．\n",
        "\n",
        "最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "23m79Eq-zmjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe1668a-6f3c-433e-d907-fd0f54e89784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Linear-7                 [-1, 1024]       2,098,176\n",
            "              ReLU-8                 [-1, 1024]               0\n",
            "            Linear-9                 [-1, 1024]       1,049,600\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 3,163,114\n",
            "Trainable params: 3,163,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.45\n",
            "Params size (MB): 12.07\n",
            "Estimated Total Size (MB): 12.53\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "## 学習\n",
        "読み込んだMNISTデータセットと作成したネットワークを用いて，学習を行います．\n",
        "\n",
        "1回の誤差を算出するデータ数（ミニバッチサイズ）を64，学習エポック数を10とします．\n",
        "\n",
        "次にデータローダーを定義します．\n",
        "データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n",
        "この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n",
        "\n",
        "次に，誤差関数を設定します．\n",
        "今回は，分類問題をあつかうため，クロスエントロピー誤差を計算するための`CrossEntropyLoss`を`criterion`として定義します．\n",
        "\n",
        "学習を開始します．\n",
        "\n",
        "各更新において，学習用データと教師データをそれぞれ`image`と`label`とします．\n",
        "学習モデルにimageを与えて各クラスの確率yを取得します．\n",
        "各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "また，認識精度も算出します．\n",
        "そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "68RE3RTa76-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a103d8-d5eb-4b2a-a1be-134637322380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, mean loss: 1.8880205393981933, mean accuracy: 0.30538, elapsed_time :11.393482208251953\n",
            "epoch: 2, mean loss: 1.3974411503601074, mean accuracy: 0.49492, elapsed_time :21.966123819351196\n",
            "epoch: 3, mean loss: 1.1734175690460205, mean accuracy: 0.57842, elapsed_time :32.350834608078\n",
            "epoch: 4, mean loss: 1.0087584886169434, mean accuracy: 0.6422, elapsed_time :42.71952223777771\n",
            "epoch: 5, mean loss: 0.8646876460647583, mean accuracy: 0.6954, elapsed_time :53.504961013793945\n",
            "epoch: 6, mean loss: 0.7322482262420654, mean accuracy: 0.74244, elapsed_time :63.91187500953674\n",
            "epoch: 7, mean loss: 0.5983668436431885, mean accuracy: 0.7886, elapsed_time :74.07920956611633\n",
            "epoch: 8, mean loss: 0.46650904767990115, mean accuracy: 0.83638, elapsed_time :84.2079541683197\n",
            "epoch: 9, mean loss: 0.34777443286895754, mean accuracy: 0.87748, elapsed_time :94.49040484428406\n",
            "epoch: 10, mean loss: 0.24586092400550844, mean accuracy: 0.9148, elapsed_time :104.93625116348267\n"
          ]
        }
      ],
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークモデルを用いて評価を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yoYVMRGLzm1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8ce475-3f7c-4607-95bc-8e0a0c838cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 0.6898\n"
          ]
        }
      ],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzl4N5rC4j5u"
      },
      "source": [
        "## 課題\n",
        "\n",
        "### 1. ネットワークの構造を変更し，認識精度の変化を確認しましょう．\n",
        "\n",
        "**ヒント：ネットワーク構造の変更としては，次のようなものが考えられます．**\n",
        "* 中間層のユニット数\n",
        "* 層の数\n",
        "* 活性化関数\n",
        "  * `nn.Tanh()`や`nn.ReLU()`, `nn.LeakyReLU()`などが考えられます．\n",
        "  * その他のPyTorchで使用できる活性化関数は[こちらページ](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)にまとめられています．\n",
        "\n",
        "※ ネットワーク構造を変更した際には，`torchsummary.summary(***)`を使用し，ネットワーク構造を変更した際のパラメータ数の変化を確認してみましょう．\n",
        "\n",
        "\n",
        "### 2. 学習の設定を変更し，認識精度の変化を確認しましょう．\n",
        "\n",
        "**ヒント：プログラムの中で変更で切る設定は次のようなものが存在します．**\n",
        "* ミニバッチサイズ\n",
        "* 学習回数（Epoch数）\n",
        "* 学習率\n",
        "* 最適化手法\n",
        "  * `torch.optim.Adagrad()`や`torch.optim.Adam()`などが考えられます．\n",
        "  * PyTorchで使用できる最適化手法は[こちらのページ](https://pytorch.org/docs/stable/optim.html#algorithms)にまとめられています．\n",
        "\n",
        "\n",
        "### 3. Data Augmentationの種類を追加して学習を行いましょう．\n",
        "\n",
        "**ヒント**\n",
        "：学習時に使用するData Augmentationは`transform_train`の部分で変更できます．\n",
        "\n",
        "```python\n",
        "transform_train = transforms.Compose([(この部分に使用するAugmentationの処理を追加) ,\n",
        "                                      transforms.ToTensor()])\n",
        "```\n",
        "\n",
        "PyTorch（torchvision）で使用可能な変換は[こちらのページ](https://pytorch.org/vision/stable/transforms.html)にまとめられています．\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentationなし #####\n",
        "#transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "#transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# augmentationあり #####\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor()])\n",
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.relu(self.conv1(x)))\n",
        "        h = self.pool(self.relu(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.relu(self.l1(h))\n",
        "        h = self.relu(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h\n",
        "\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))\n",
        "\n",
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iigkkNpdCA4c",
        "outputId": "f9119284-1f2a-42d7-f559-3eb4f521a06a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 88340769.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=1)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Linear-7                 [-1, 1024]       2,098,176\n",
            "              ReLU-8                 [-1, 1024]               0\n",
            "            Linear-9                 [-1, 1024]       1,049,600\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 3,163,114\n",
            "Trainable params: 3,163,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.45\n",
            "Params size (MB): 12.07\n",
            "Estimated Total Size (MB): 12.53\n",
            "----------------------------------------------------------------\n",
            "epoch: 1, mean loss: 1.8980891024780273, mean accuracy: 0.30086, elapsed_time :17.426478624343872\n",
            "epoch: 2, mean loss: 1.3919591477966309, mean accuracy: 0.49764, elapsed_time :34.826616287231445\n",
            "epoch: 3, mean loss: 1.1758876003265382, mean accuracy: 0.5791, elapsed_time :51.87469792366028\n",
            "epoch: 4, mean loss: 1.0337009620666504, mean accuracy: 0.63372, elapsed_time :69.10634732246399\n",
            "epoch: 5, mean loss: 0.9322692156982422, mean accuracy: 0.67056, elapsed_time :85.68778204917908\n",
            "epoch: 6, mean loss: 0.8534375823974609, mean accuracy: 0.69984, elapsed_time :102.52094602584839\n",
            "epoch: 7, mean loss: 0.7796760222625733, mean accuracy: 0.72478, elapsed_time :119.79312229156494\n",
            "epoch: 8, mean loss: 0.7212504901885987, mean accuracy: 0.74626, elapsed_time :136.48598718643188\n",
            "epoch: 9, mean loss: 0.6669823175430298, mean accuracy: 0.76714, elapsed_time :153.9218327999115\n",
            "epoch: 10, mean loss: 0.6195326516342163, mean accuracy: 0.78196, elapsed_time :170.5083475112915\n",
            "test accuracy: 0.7262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentationなし #####\n",
        "#transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "#transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# augmentationあり #####\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor()])\n",
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.relu(self.conv1(x)))\n",
        "        h = self.pool(self.relu(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.relu(self.l1(h))\n",
        "        h = self.relu(self.l2(h))\n",
        "        h = self.relu(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h\n",
        "\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))\n",
        "\n",
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0wM4lorDhw0",
        "outputId": "0bc43393-020f-4daf-c0e2-ab61a66c8af0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=1)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Linear-7                 [-1, 1024]       2,098,176\n",
            "              ReLU-8                 [-1, 1024]               0\n",
            "            Linear-9                 [-1, 1024]       1,049,600\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                 [-1, 1024]       1,049,600\n",
            "             ReLU-12                 [-1, 1024]               0\n",
            "           Linear-13                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 4,212,714\n",
            "Trainable params: 4,212,714\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.47\n",
            "Params size (MB): 16.07\n",
            "Estimated Total Size (MB): 16.55\n",
            "----------------------------------------------------------------\n",
            "epoch: 1, mean loss: 2.008196323852539, mean accuracy: 0.25444, elapsed_time :17.912976026535034\n",
            "epoch: 2, mean loss: 1.5006767121887208, mean accuracy: 0.45388, elapsed_time :36.055312395095825\n",
            "epoch: 3, mean loss: 1.296488242416382, mean accuracy: 0.53174, elapsed_time :53.68275308609009\n",
            "epoch: 4, mean loss: 1.1433374684906006, mean accuracy: 0.5902, elapsed_time :70.54156875610352\n",
            "epoch: 5, mean loss: 1.0154389260101317, mean accuracy: 0.63876, elapsed_time :87.77009558677673\n",
            "epoch: 6, mean loss: 0.9136844097900391, mean accuracy: 0.67808, elapsed_time :105.12115931510925\n",
            "epoch: 7, mean loss: 0.832418833732605, mean accuracy: 0.709, elapsed_time :122.23349404335022\n",
            "epoch: 8, mean loss: 0.7716234349060058, mean accuracy: 0.72722, elapsed_time :140.1571228504181\n",
            "epoch: 9, mean loss: 0.7144781859588623, mean accuracy: 0.74874, elapsed_time :157.29749655723572\n",
            "epoch: 10, mean loss: 0.6589492736816406, mean accuracy: 0.76908, elapsed_time :175.22183227539062\n",
            "test accuracy: 0.7164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentationなし #####\n",
        "#transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "#transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# augmentationあり #####\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor()])\n",
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.relu(self.conv1(x)))\n",
        "        h = self.pool(self.relu(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.relu(self.l1(h))\n",
        "        h = self.relu(self.l2(h))\n",
        "        h = self.relu(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h\n",
        "\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 15\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))\n",
        "\n",
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8cO7xdcDnur",
        "outputId": "a32df6bb-1656-4979-f271-881f97e44b2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=1)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Linear-7                 [-1, 1024]       2,098,176\n",
            "              ReLU-8                 [-1, 1024]               0\n",
            "            Linear-9                 [-1, 1024]       1,049,600\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                 [-1, 1024]       1,049,600\n",
            "             ReLU-12                 [-1, 1024]               0\n",
            "           Linear-13                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 4,212,714\n",
            "Trainable params: 4,212,714\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.47\n",
            "Params size (MB): 16.07\n",
            "Estimated Total Size (MB): 16.55\n",
            "----------------------------------------------------------------\n",
            "epoch: 1, mean loss: 2.074813784942627, mean accuracy: 0.2186, elapsed_time :17.356157302856445\n",
            "epoch: 2, mean loss: 1.4907837702941895, mean accuracy: 0.45432, elapsed_time :35.15144205093384\n",
            "epoch: 3, mean loss: 1.2600477979278564, mean accuracy: 0.54676, elapsed_time :52.20647621154785\n",
            "epoch: 4, mean loss: 1.0855857403564453, mean accuracy: 0.6153, elapsed_time :70.01156830787659\n",
            "epoch: 5, mean loss: 0.9818687775421142, mean accuracy: 0.65196, elapsed_time :87.06331872940063\n",
            "epoch: 6, mean loss: 0.8922721716690063, mean accuracy: 0.6851, elapsed_time :104.78539729118347\n",
            "epoch: 7, mean loss: 0.818193851928711, mean accuracy: 0.7107, elapsed_time :121.95782828330994\n",
            "epoch: 8, mean loss: 0.7550664218902587, mean accuracy: 0.73516, elapsed_time :139.07517051696777\n",
            "epoch: 9, mean loss: 0.70089301612854, mean accuracy: 0.7539, elapsed_time :156.5359070301056\n",
            "epoch: 10, mean loss: 0.6454639157104493, mean accuracy: 0.77338, elapsed_time :173.60823678970337\n",
            "epoch: 11, mean loss: 0.6048449311637878, mean accuracy: 0.78772, elapsed_time :191.23624324798584\n",
            "epoch: 12, mean loss: 0.5600245172500611, mean accuracy: 0.80328, elapsed_time :208.14296889305115\n",
            "epoch: 13, mean loss: 0.5163109875679016, mean accuracy: 0.81774, elapsed_time :225.48191618919373\n",
            "epoch: 14, mean loss: 0.48130927289962766, mean accuracy: 0.83166, elapsed_time :242.8709590435028\n",
            "epoch: 15, mean loss: 0.4484021294403076, mean accuracy: 0.84042, elapsed_time :259.85591673851013\n",
            "test accuracy: 0.7433\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}